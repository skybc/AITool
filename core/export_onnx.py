"""
ONNX å¯¼å‡ºè„šæœ¬ - å°† PyTorch æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼
ç”¨äºéƒ¨ç½²åˆ°æ¨ç†å¼•æ“å’Œè¾¹ç¼˜è®¾å¤‡
"""

import argparse
import os
from pathlib import Path
import torch
import numpy as np

try:
    import onnx
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False

from ultralytics import YOLO


class ONNXExporter:
    """ONNX æ¨¡å‹å¯¼å‡ºå™¨"""
    
    def __init__(self, weights_path: str, output_dir: str = './'):
        """åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        å‚æ•°:
            weights_path: PyTorch æƒé‡æ–‡ä»¶è·¯å¾„ (.pt)
            output_dir: è¾“å‡ºç›®å½•
        """
        self.weights_path = Path(weights_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        if not self.weights_path.exists():
            raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weights_path}")
        
        print(f"âœ… åˆå§‹åŒ–å¯¼å‡ºå™¨")
        print(f"   æƒé‡: {weights_path}")
        print(f"   è¾“å‡º: {output_dir}")
    
    def export(
        self,
        opset_version: int = 12,
        simplify: bool = True,
        optimize_model: bool = True,
    ) -> str:
        """å¯¼å‡ºä¸º ONNX æ ¼å¼
        
        å‚æ•°:
            opset_version: ONNX OpSet ç‰ˆæœ¬
            simplify: æ˜¯å¦ä½¿ç”¨ onnx-simplifier ç®€åŒ–æ¨¡å‹
            optimize_model: æ˜¯å¦ä¼˜åŒ–æ¨¡å‹
            
        è¿”å›:
            å¯¼å‡ºçš„ ONNX æ–‡ä»¶è·¯å¾„
        """
        print(f"\nğŸ”„ å¼€å§‹å¯¼å‡º ONNX æ¨¡å‹...")
        
        # åŠ è½½æ¨¡å‹
        model = YOLO(str(self.weights_path))
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        onnx_path = self.output_dir / self.weights_path.stem + '.onnx'
        
        # å¯¼å‡º
        model.export(
            format='onnx',
            opset=opset_version,
            simplify=simplify,
        )
        
        # å®˜æ–¹å¯¼å‡ºé€šå¸¸åœ¨åŸè·¯å¾„é™„è¿‘ï¼Œæˆ‘ä»¬éœ€è¦å¤åˆ¶åˆ°ç›®æ ‡ä½ç½®
        import shutil
        # YOLO11 å®˜æ–¹å¯¼å‡ºçš„æ–‡ä»¶
        default_onnx = self.weights_path.parent / (self.weights_path.stem + '.onnx')
        if default_onnx.exists() and default_onnx != onnx_path:
            shutil.copy(default_onnx, onnx_path)
        
        print(f"âœ… å·²å¯¼å‡º ONNX æ¨¡å‹: {onnx_path}")
        
        return str(onnx_path)
    
    def validate_onnx(self, onnx_path: str, test_image_shape: tuple = (1, 3, 640, 640)):
        """éªŒè¯ ONNX æ¨¡å‹
        
        å‚æ•°:
            onnx_path: ONNX æ–‡ä»¶è·¯å¾„
            test_image_shape: æµ‹è¯•è¾“å…¥å½¢çŠ¶ (B, C, H, W)
        """
        if not ONNX_AVAILABLE:
            print("âš ï¸  onnxruntime æœªå®‰è£…ï¼Œè·³è¿‡éªŒè¯")
            return
        
        print(f"\nâœ”ï¸ éªŒè¯ ONNX æ¨¡å‹...")
        
        # åŠ è½½ ONNX æ¨¡å‹
        onnx_model = onnx.load(onnx_path)
        
        # æ£€æŸ¥æ¨¡å‹
        try:
            onnx.checker.check_model(onnx_model)
            print(f"âœ… ONNX æ¨¡å‹æ ¼å¼æ­£ç¡®")
        except Exception as e:
            print(f"âŒ ONNX æ¨¡å‹æ ¼å¼é”™è¯¯: {e}")
            return
        
        # ä½¿ç”¨ onnxruntime æµ‹è¯•æ¨ç†
        try:
            session = ort.InferenceSession(onnx_path)
            
            # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
            input_name = session.get_inputs()[0].name
            output_names = [o.name for o in session.get_outputs()]
            
            print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            print(f"   è¾“å…¥: {input_name} {session.get_inputs()[0].shape}")
            for output in session.get_outputs():
                print(f"   è¾“å‡º: {output.name} {output.shape}")
            
            # æ‰§è¡Œæµ‹è¯•æ¨ç†
            test_input = np.random.randn(*test_image_shape).astype(np.float32)
            
            import time
            start = time.time()
            outputs = session.run(output_names, {input_name: test_input})
            elapsed = time.time() - start
            
            print(f"\nâš¡ æ¨ç†æ€§èƒ½:")
            print(f"   è¾“å…¥å½¢çŠ¶: {test_image_shape}")
            print(f"   æ¨ç†æ—¶é—´: {elapsed*1000:.2f} ms")
            print(f"   è¾“å‡ºæ•°é‡: {len(outputs)}")
            
            print(f"\nâœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡!")
            
        except Exception as e:
            print(f"âŒ ONNX æ¨ç†å¤±è´¥: {e}")
    
    def print_model_info(self, onnx_path: str):
        """æ‰“å°æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        if not ONNX_AVAILABLE:
            return
        
        onnx_model = onnx.load(onnx_path)
        graph = onnx_model.graph
        
        print(f"\nğŸ“‹ ONNX æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
        print(f"\nè¾“å…¥:")
        for input_tensor in graph.input:
            print(f"  - {input_tensor.name}: {[d.dim_value for d in input_tensor.type.tensor_type.shape.dim]}")
        
        print(f"\nè¾“å‡º:")
        for output_tensor in graph.output:
            print(f"  - {output_tensor.name}: {[d.dim_value for d in output_tensor.type.tensor_type.shape.dim]}")
        
        print(f"\nç®—å­æ•°é‡: {len(graph.node)}")
        
        # ç»Ÿè®¡ç®—å­ç±»å‹
        op_types = {}
        for node in graph.node:
            op_types[node.op_type] = op_types.get(node.op_type, 0) + 1
        
        print(f"\nç®—å­ç±»å‹ç»Ÿè®¡:")
        for op_type, count in sorted(op_types.items(), key=lambda x: -x[1])[:10]:
            print(f"  - {op_type}: {count}")
        
        # æ¨¡å‹å¤§å°
        import os
        size_mb = os.path.getsize(onnx_path) / (1024 * 1024)
        print(f"\næ¨¡å‹å¤§å°: {size_mb:.2f} MB")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ONNX å¯¼å‡ºè„šæœ¬')
    parser.add_argument('--weights', type=str, required=True, help='PyTorch æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='./', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--opset', type=int, default=12, help='ONNX OpSet ç‰ˆæœ¬')
    parser.add_argument('--simplify', action='store_true', help='ç®€åŒ– ONNX æ¨¡å‹')
    parser.add_argument('--optimize', action='store_true', help='ä¼˜åŒ–æ¨¡å‹')
    parser.add_argument('--validate', action='store_true', help='éªŒè¯å¯¼å‡ºçš„æ¨¡å‹')
    parser.add_argument('--info', action='store_true', help='æ‰“å°æ¨¡å‹ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯¼å‡ºå™¨
    exporter = ONNXExporter(args.weights, args.output)
    
    # å¯¼å‡º
    onnx_path = exporter.export(
        opset_version=args.opset,
        simplify=args.simplify,
        optimize_model=args.optimize,
    )
    
    # éªŒè¯
    if args.validate:
        exporter.validate_onnx(onnx_path)
    
    # æ‰“å°ä¿¡æ¯
    if args.info:
        exporter.print_model_info(onnx_path)
    
    print(f"\nâœ… å¯¼å‡ºå®Œæˆ!")
    print(f"   ONNX æ–‡ä»¶: {onnx_path}")


if __name__ == '__main__':
    main()
